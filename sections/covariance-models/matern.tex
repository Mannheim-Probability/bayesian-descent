\subsection{Matérn}

The Matérn model \(\C_\nu\) encompasses the nugget effect for \(\nu=0\),
the exponential model for \(\nu=\tfrac12\) and the squared exponential model
for \(\nu=\infty\). The smoothness of the model increases with increasing
\(\nu\). While the exponential covariance model results in a random field which
is not yet differentiable, larger \(\nu\) result in increasing
differentiability\fxnote{source}. For \(\nu = p+\tfrac12\) with \(p\in\nat_0\) there exists the
simplified formula\fxnote{source}
\begin{align}
	\C_{p+\tfrac12}(\|\step\|)
	&= \sigma^2 \exp\left(- \tfrac{\sqrt{2p+1} \|\step\|}{s}\right)\tfrac{p!}{(2p)!}
	\sum_{k=0}^p \tfrac{(2p-k)!}{(p-k)!k!}\left(\tfrac{2\sqrt{2p+1}}{s}\|\step\|\right)^k
	\nonumber
	\\
	\label{eq: matern abstractions}
	&= \sigma^2 \exp\left(- \mf(\|\step\|)\right)
	\sum_{k=0}^p \underbrace{\tfrac{p!}{(2p)!}\tfrac{(2p-k)!}{(p-k)!k!}2^k}_{=:\mcoeff(k)}
	\mf(\|\step\|)^k
\end{align}
With this we can take the derivative
\begin{align*}
	\C_{p+\frac12}'(\lr)
	&= -\sigma^2\exp(-\mf(\lr))\mf'(\lr)\underbrace{\bigg[
		\sum_{k=0}^p\mcoeff(k)\mf(\lr)^k
		- \sum_{k=1}^p \mcoeff(k)k\mf(\lr)^{k-1}
	\bigg]}_{
		=\mcoeff(p)\mf(\lr)^p + \sum_{k=0}^{p-1}[ \mcoeff(k) - (k+1)\mcoeff(k+1) ]\mf(\lr)^k
	}\\
	\overset{\eqref{def: dcoeff}}&=
	-\sigma^2\exp\Big(-\mf(\lr)\Big)\mf'(\lr)\sum_{k=0}^p \dcoeff(k-1)\mf(\lr)^k\\
	\overset{\eqref{eq: dcoeff(k)}}&=
	-\sigma^2\exp\Big(-\mf(\lr)\Big)\mf'(\lr)\sum_{k=0}^{p-1} \dcoeff(k)\mf(\lr)^{k+1}\\
	&=-\frac{\sigma^2(2p+1)}{s^2}\lr\exp\Big(-\mf(\lr)\Big)\sum_{k=0}^{p-1} \dcoeff(k)\mf(\lr)^k.
\end{align*}
Where we used \(\mf'(\lr)\mf(\lr) = \tfrac{2p+1}{s^2}\lr\) and define
\begin{equation}\label{def: dcoeff}
	\dcoeff(k):= \begin{cases}
		\mcoeff(k+1) - (k+2)\mcoeff(k+2) & k\le p-2\\
		\mcoeff(p) & k = p-1
	\end{cases}
\end{equation}
and note that
\begin{align}
	\nonumber
	\dcoeff(k)
	&= \mcoeff(k+1) - (k+2)\mcoeff(k+2)\\
	\nonumber
	&= \frac{p}{(2p)!}\left[
		\frac{(2p-(k+1))!}{(p-(k+1))!(k+1)!}2^{k+1}
		- (k+2)\frac{(2p-(k+2))!}{(p-(k+2))!(k+2)!}2^{k+2}
	\right]\\
	\nonumber
	&= \frac{p}{(2p)!}\frac{(2p - (k+2))!}{(p-(k+1))!(k+1)!}2^{k+1}
	\bigg[(2p-(k+1))- (p-(k+1))2^1\bigg]\\
	\nonumber
	&= \frac{p}{(2p)!}\frac{(2(p-1) -k)!}{((p-1)-k)!(k+1)!}2^{k+1}[k+1]\\
	\label{eq: dcoeff(k)}
	&= \begin{cases}
		% \frac{2p}{(2p)!}\frac{(2(p-1) -k)!}{((p-1)-k)!k!}2^k =
		\frac{\mcoeff[p-1](k)}{2p-1} & 0 \le k \le p-2\\
		0 & k=-1.
	\end{cases}
\end{align}
We can further calculate a few special cases
\begin{align}
	\label{eq: mcoeff 0}
	\mcoeff(0)
	&= \frac{\bcancel{p!}}{\cancel{(2p)!}}\frac{\cancel{(2p-0)!}}{\bcancel{(p-0)!}0!}2^0
	= 1
	\qquad
	&& p\ge 0\\
	\label{eq: mcoeff 1}
	\mcoeff(1)
	&= \frac{p!}{(2p)!}\frac{(2p-1)!}{(p-1)!1!}2^1 = \frac{2p}{2p} = 1 
	\qquad
	&& p\ge 1\\
	\mcoeff(p)
	\label{eq: mcoeff p}
	&= \frac{p!}{(2p)!}\frac{\cancel{(2p-p)!}}{(p-p)!\cancel{p!}}2^p
	= \frac{1}{(2p-1)!!}
	&& p \ge 1
\end{align}
%
Assuming \(\C(\lr) = \sqC(\lr^2)\) implies \(\sqC'(\lr^2) = \frac1{2\lr}\C'(\lr)\).
So we have
\begin{equation*}
	\sqC'(\lr^2)
	=-\frac{\sigma^2(2p+1)}{2s^2}
	\exp\Big(-\mf(\lr)\Big)\sum_{k=0}^{p-1} \dcoeff(k)\mf(\lr)^k
\end{equation*}
with
\begin{equation*}
	\dcoeff(k) = \begin{cases}
		\frac{\mcoeff[p-1](k)}{2p-1} & 0 \le k \le p-2\\
		\mcoeff(p) = \frac{1}{(2p-1)!!} & k=p-1.
	\end{cases}
\end{equation*}

\begin{theorem}
	Assuming \(\Loss\) is a \textbf{centered} random field with Matérn covariance
	\(\C_{p+\frac12}\) for \(p\in\nat\), we have
	\begin{align*}
		\step(\hat{\lr})
		&= \argmin_{d}
		\BLUE[\Loss(\param + \step) - \Loss(\param)\mid \grad\Loss(\param)]\\
		\hat{\lr}
		&= \argmax_{\lr\ge0}\left[
			\exp\left(-\tfrac{\sqrt{2p+1}}{s}\lr\right)
			\sum_{k=0}^{p-1}\tfrac{\dcoeff(k)}{\dcoeff(0)}\left(\tfrac{\sqrt{2p+1}}{s}\right)^k \lr^{k+1}
		\right]
	\end{align*}
	So we have for
	\begin{itemize}
		\item \(p=1\)
		\begin{equation*}
			\hat{\lr} = \frac{s}{\sqrt{3}}
		\end{equation*}

		\item \(p=2\)
		\begin{equation*}
			\hat{\lr}
			= \frac{s}{\sqrt{5}}\frac{1+\sqrt{5}}2
		\end{equation*}
	\end{itemize}
\end{theorem}

\begin{proof}
	Using Remark~\ref{rem: replace variogram with covariance} and
	Theorem~\ref{thm: bayesian descent} we only need the maximum of
	\begin{align*}
		\lr\frac{\sqC'(\lr^2)}{\sqC'(0)}
		&= \lr \frac{
			\exp(-\mf(\lr))\sum_{k=0}^{p-1}\dcoeff(k)\mf(\lr)^k
		}{\exp(0)\dcoeff(0)0^0}\\
		\overset{\eqref{eq: mcoeff 0}}&=
		\lr\exp\left(-\tfrac{\sqrt{2p+1}}{s}|\lr|\right)
		\sum_{k=0}^{p-1}\tfrac{\dcoeff(k)}{\dcoeff(0)}\left(\tfrac{\sqrt{2p+1}}{s}|\lr|\right)^k.
	\end{align*}
	As the equation above is negative for \(\lr \le 0\) but positive for \(\lr \ge 0\)
	as \(\dcoeff(k)\ge 0\), we can assume without loss of generality \(\lr\ge 0\)
	when maximizing. Additionally the term is zero for \(\lr=0\) positive for
	\(\lr\ge0\) and tends towards zero for \(\lr\to\infty\). Therefore there
	exists at least one maximum.

	Taking the derivative for \(\lr\ge 0\) results in
	\begin{equation}\label{eq: derivative of matern grad cov}
		\exp\left(-\tfrac{\sqrt{2p+1}}{s}\lr\right)\left[
			-\sum_{k=0}^{p-1}\tfrac{\dcoeff(k)}{\dcoeff(0)}\left(\tfrac{\sqrt{2p+1}}{s}\lr\right)^{k+1}
			+\sum_{k=0}^{p-1}\tfrac{\dcoeff(k)}{\dcoeff(0)}(k+1)\left(\tfrac{\sqrt{2p+1}}{s}\lr\right)^k 
		\right]
	\end{equation}
	So for the first order condition we require
	\begin{align*}
		0 &= 1 + \sum_{k=1}^{p-1}
		\left[(k+1)\tfrac{\dcoeff(k)}{\dcoeff(0)} - \tfrac{\dcoeff(k-1)}{\dcoeff(0)}\right]
		\left(\tfrac{\sqrt{2p+1}}{s}\lr\right)^k
		- \tfrac{\dcoeff(p-1)}{\dcoeff(0)}\left(\tfrac{\sqrt{2p+1}}{s}\lr\right)^p.
	\end{align*}
	Let us have a look at the coefficients 
	\begin{align*}
		\dcoeff(0)
		&= \frac{\mcoeff[p-1](0)}{2p-1}
		\overset{\eqref{eq: mcoeff 0}}=\frac{1}{2p-1}\\
		\dcoeff(p-1)
		&= \mcoeff(p) \overset{\eqref{eq: mcoeff p}}= \frac{1}{(2p-1)!!}\\
		\frac{\dcoeff(k)}{\dcoeff(0)} 
		&= \mcoeff[p-1](k) & 0\le k \le p-2
	\end{align*}
	Now let us consider \(p=1\). Here we have
	\begin{equation*}
		0 = 1 - \tfrac{\sqrt{3}}{s}\lr
	\end{equation*}
	and therefore \(\hat{\lr}=\frac{s}{\sqrt{3}}\).

	For \(p=2\) we have
	\begin{equation*}
		0 = 1 - \left(\tfrac{\sqrt{5}}{s}\lr\right)^2
		+ \underbrace{\biggl[2\frac{\dcoeff[2](p-1)}{\dcoeff[2](0)} - \mcoeff[1](0)\biggr]}_{
			= 2\frac{2\cdot 2-1}{(2\cdot 2 -1)!!} - 1
			=1\quad \mathrlap{\eqref{eq: mcoeff 0}, \eqref{eq: mcoeff 1}}
		}\tfrac{\sqrt{5}}{s}\lr
	\end{equation*}
	So we want to find \(\tfrac{\sqrt{5}}{s}\lr\) which solves
	\begin{equation*}
		0 = x^2 - x - 1.
	\end{equation*}
	\(\lr\ge0\) implies only one solution remains
	\begin{equation*}
		\frac{\sqrt{5}}{s}\hat{\lr}
		= \left(\frac12 + \frac{\sqrt{1 + 4}}{2}\right)
		= \frac{1+\sqrt{5}}2.
		\qedhere
	\end{equation*}
\end{proof}

\input{theorems/covariance_models/matern.tex}

\begin{proof}
	By Theorem~\ref{thm: bayesian descent}	we have
	\begin{equation*}
		\hat{\lr}	
		= \argmin_{\lr}\frac{\sqC(\lr^2)}{\sqC(0)} \frac{\Loss(\param)}{\|\grad\Loss(\param)\|}
		-  \lr\frac{\sqC'(\lr^2)}{\sqC'(0)}
	\end{equation*}
	with
	\begin{align*}
		\frac{\sqC(\lr^2)}{\sqC(0)}
		&= \frac{\C_{p+\frac12}(\lr)}{\C_{p+\frac12}(0)}
		= \frac{\sigma^2\exp(-\mf(\lr))\sum_{k=0}^p \mcoeff(k)\mf(\lr)^k}{\sigma^2\exp(-0)\sum_{k=0}^p \mcoeff(k)0^k}
		\\
		&= \exp(-\mf(\lr))\sum_{k=0}^p \mcoeff(k)\mf(\lr)^k.
	\end{align*}
	Taking the derivative of this first term, we get
	\begin{align*}
		&\frac{d}{d\lr}\frac{\sqC(\lr^2)}{\sqC(0)}\\
		&= \exp(-\mf(\lr))\mf'(\lr)\left[
			- \sum_{k=0}^p \mcoeff(k)\mf(\lr)^k + \sum_{k=1}^p \mcoeff(k)k\mf(\lr)^{k-1}
		\right]\\
		&= -\exp(-\mf(\lr))\mf'(\lr)\biggl[
			\mcoeff(p)\mf(\lr)^p + \underbrace{\sum_{k=0}^{p-1} [\mcoeff(k)-(k+1)\mcoeff(k+1)]\mf(\lr)^k}_{\overset{\eqref{eq: mcoeff 0},\eqref{eq: mcoeff 1}}=\sum_{k=1}^{p-1} [\mcoeff(k)-(k+1)\mcoeff(k+1)]\mf(\lr)^k}
		\biggr].
	\end{align*}
	Recall that in \eqref{eq: derivative of matern grad cov} we have already
	calculated the derivative of the second therm (the gradient covariance), i.e.
	\begin{align*}
		&\frac{d}{d\lr}\lr\frac{\sqC'(\lr^2)}{\sqC'(0)}\\
		&=\exp\left(-\mf(\lr)\right)\left[
			-\sum_{k=0}^{p-1}\tfrac{\dcoeff(k)}{\dcoeff(0)}\mf(\lr)^{k+1}
			+\sum_{k=0}^{p-1}\tfrac{\dcoeff(k)}{\dcoeff(0)}(k+1)\mf(\lr)^k 
		\right]\\
		&=\exp\left(-\mf(\lr)\right)
		\biggl[
			1 + \sum_{k=1}^{p-1}
			\left[(k+1)\tfrac{\dcoeff(k)}{\dcoeff(0)} - \tfrac{\dcoeff(k-1)}{\dcoeff(0)}\right]
			\mf(\lr)^k
			- \underbrace{\tfrac{\dcoeff(p-1)}{\dcoeff(0)}}_{=(2p-1)\mathrlap{\mcoeff(p)}}\mf(\lr)^p
		\biggr].
	\end{align*}
	Defining
	\begin{equation*}
		\Delta_\Loss = -\mf'(\lr) \frac{\Loss(\param)}{\|\grad\Loss(\param)\|}
	\end{equation*}
	and multiplying the first order condition by \(\exp(\mf(\lr))\) we get
	\begin{align*}
		0\overset!&=
		\exp(\mf(\lr))\frac{d}{d\lr}\left[
			\frac{\sqC(\lr^2)}{\sqC(0)}\frac{\Loss(\param)}{\|\nabla\Loss(\param)\|}
			- \lr\frac{\sqC'(\lr^2)}{\sqC'(0)}
		\right]\\
		&=\begin{aligned}[t]
			&-1 + \left(\Delta_\Loss + (2p-1)\right)\mcoeff(p)\mf(\lr)^p
			\\
			&+ \sum_{k=1}^{p-1}
				\biggl(\Delta_\Loss
				[\mcoeff(k)-(k+1)\mcoeff(k+1)]
				-\left[(k+1)\tfrac{\dcoeff(k)}{\dcoeff(0)}-\tfrac{\dcoeff(k-1)}{\dcoeff(0)}\right]
				\biggr)
				\mf(\lr)^k
		\end{aligned}
	\end{align*}
	So for \(p=1\) we have
	\begin{align*}
		0\overset!&=
		-1 + \left(\Delta_\Loss + (2\cdot 1-1)\right)\mcoeff(p)\mf(\lr)^p\\
		&= -1 + \left(1- \frac{\sqrt{3}}{s}\frac{\Loss(\param)}{\|\grad\Loss(\param)\|}\right)
		\frac{\sqrt{3}}{s}\lr,
	\end{align*}
	which implies	
	\[
		\hat{\lr}
		= \frac{1}{\frac{\sqrt{3}}{s}\left(
			1- \frac{\sqrt{3}}{s}\frac{\Loss(\param)}{\|\grad\Loss(\param)\|}
		\right)}.
	\]
	For \(p=2\) we have
	\begin{align*}
		0\overset!&=
		\begin{aligned}[t]
			&-1
			+ \left(3-\frac{\sqrt{5}}{s}\frac{\Loss(\param)}{\|\grad\Loss(\param)\|}\right)
			\frac{1}{3!!}\frac{5}{s^2}\lr^2\\
			&+ \left(
				-\frac{\sqrt{5}}{s}\frac{\Loss(\param)}{\|\grad\Loss(\param)\|}
				[\mcoeff[2](1) - 2\mcoeff[2](2)] -
				\bigl[2\tfrac{\mcoeff[2](2)}{\dcoeff[2](0)} - \mcoeff[1](0)\bigr]
			\right)\frac{\sqrt{5}}s \lr
		\end{aligned}\\
		&=
		\begin{aligned}[t]
			&-1
			+ \left(1-\frac{\sqrt{5}}{3s}\frac{\Loss(\param)}{\|\grad\Loss(\param)\|}\right)
			\frac{5}{s^2}\lr^2\\
			&+ \underbrace{\left(
				-\frac{\sqrt{5}}{s}\frac{\Loss(\param)}{\|\grad\Loss(\param)\|}
				\bigl[1 - \tfrac2{(4-1)!!}\bigr] -
				\bigl[2\tfrac{(4-1)}{(4-1)!!} - 1\bigr]
			\right)}_{
				= -\frac{\sqrt{5}}{3s}\frac{\Loss(\param)}{\|\grad\Loss(\param)\|} - 1
			}\frac{\sqrt{5}}s \lr
		\end{aligned}\\
		&= -1
		- \left(1-\frac{\sqrt{5}}{3s}\frac{\Loss(\param)}{\|\grad\Loss(\param)\|}\right)
		\frac{\sqrt{5}}s \lr
		+ \left(1-\frac{\sqrt{5}}{3s}\frac{\Loss(\param)}{\|\grad\Loss(\param)\|}\right)
		\left(\frac{\sqrt{5}}{s}\lr\right)^2
	\end{align*}
	\(\frac{\sqrt{5}}{s}\hat{\lr}\) is therefore the positive solution of
	\begin{equation*}
		0= ax^2 - ax - 1
	\end{equation*}
	with \(a= \left(1-\frac{\sqrt{5}}{3s}\frac{\Loss(\param)}{\|\grad\Loss(\param)\|}\right)\).
	In other words we have
	\begin{equation*}
		\frac{\sqrt{5}}{s}\hat{\lr} = \frac{1+\sqrt{1+4/a}}{2}.
	\end{equation*}
	Plugging \(a\) back in results in the claim.
\end{proof}
